{
  
    
        "post0": {
            "title": "【译】深度学习中的那些重要想法——历史简要回顾",
            "content": "翻译自原文 . 深度学习这个领域瞬息，大量研究论文和想法会让人不知所措。即便是经验老道的研究员也很难跟公关(company PR)说真正的突破是什么。本文的目的是回顾那些经得住时间考验的想法，且这些想法也许更加靠谱。这些想法以及其发展被反复使用，堪称劳模。 . 如果你是今天才开始接触深度学习，理解和实现这当中每一项技术会给你带来很好的基础，去理解近期的研究以及着手于自己的项目。这是最好的入门方式。而且按历史先后顺序来学习，能更好地理解当前技术出自哪里、为何出现。换言之，这里会列出尽量少的且必要的知识，去理解现代深度学习的研究。 . 深度学习的一个独特之处是它的应用（计算机视觉、自然语言、语音处理、强化学习等）都共同涉及到大多数技术，就像CV（计算机视觉）领域的专家可以很快地着手NLP（自然语言处理）研究。具体的网络结构会有所不同，但概念、方法，甚至代码都是几近相同的。这里会尝试列出不同领域的想法，但关于这个需要注意几点： . 本文目标不是剖析这些技术，也不会给出代码。冗长复杂的论文浓缩成一段并不是件简单的事。相反，这里会给出每个技术的概况、它的历史上下文，和论文及其实现的链接。这里极力推荐用PyTorch从零开始复现这些论文的成果，而不是在已有代码基础上改或者采用高级库。 . | 这个列表是基于作者的知识，有很多令人兴奋的子领域，作者尚未接触。本文会集中在上面提到的那些领域，毕竟大多数人也是更加关注这些。 . | 本文只讨论一些官方/半官方的可用的开源实现。有些研究很难复现，因为涉及很大的工程挑战，比如DeepMind的AlphaGo和OpenAI的Dota2 AI。 . | 有些技术会在同一时间内公布，而这里不会一一列出。全面不是本文的目的，照顾新手才是，所以要挑那些涵盖域较广的想法。比如，目前有上百种GAN的变体，但要理解GAN的概念，随便学哪个都行。 . | . 2012 - 用AlexNet和Dropout处理ImageNet . 论文: . ImageNet Classification with Deep Convolutional Neural Networks (2012) . | Improving neural networks by preventing co-adaptation of feature detectors (2012) . | One weird trick for parallelizing convolutional neural networks (2014) . | . 实现： . AlexNet in PyTorch . | AlexNet in TensorFlow . | . . AlexNet被认为近期深度学习和人工智能爆发时期的代表，它是之前出自Yann LeCun之手的LeNet基础上发展来的深度卷积神经网络。得益于GPU的强大算力和先进的算法，Alexnet在ImageNet数据集分类问题上击败了当时的所有方法，证明了神经网络确实可行。AlexNet也是第一个使用Dropout的网络，而如今Dropout成为了提升深度学习模型泛化能力的关键组件。 . AlexNet的结构、卷积层序列、ReLU激活函数和最大池化层，成为了后来CV构架拓展和建立的公认标准。如今像PyTorch的软件库非常强大，加上对比近期的网络结构，AlexNet显然更加简单，所以可以通过几行代码就可以实现AlexNet。但值得注意的是，包括上面链接，很多AlexNet的实现多多少少会有些区别，具体可以看One weird trick for parallelizing convolutional neural networks。 . 2013 - 用深度强化学习玩雅达利 . 论文： . Playing Atari with Deep Reinforcement Learning (2013) | . 实现： . DQN in PyTorch . | DQN in TensorFlow . | . . 基于近期图像识别的重大突破和显卡的快速发展，DeepMind的一个团队设法训练一个网络，通过输入原生像素来玩雅达利游戏。更厉害的是，在没有告知任何游戏规则的前提下，用相同的神经网络结构去学习7种不同的游戏，充分展现了这方法的泛化能力。 . 强化学习不同于像图像分类的监督学习，前者需要一个代理在一定时间步骤内获得最大奖励（比如赢得比赛），而不是预测一个标签。因为代理直接与环境交互，且每个动作都会影响环境，所以训练样本不是独立同分布。这使得许多机器学习模型的训练不稳定，这可以通过经验回放（experience replay）解决。 . 尽管这方面没有算法上特别瞩目的革新，但这项研究巧妙地将现有的技术结合起来，包括GPU上训练的卷积神经网络和经验回访，加上一点数据处理的技巧，就能达到出乎意料的出色效果。这给了人们相当的自信，去挑战用深度强化学习解决更复杂的任务，比如围棋、Dota 2、星际争霸2等等。 . 此后，雅达利游戏已经称为强化学习研究的标准基准。最初的方法只是达到在7款游戏上击败人类，但多年来的发展和进步，现在的方法开始在更多的游戏上击败人类。尤其一款以需要长期规划著名的游戏叫《蒙特祖玛的复仇》（ Montezuma’s Revenge），被认为是最难解决的问题。直到最近，这些技术才在全部57款游戏中击败人类。 . 2014 - 采用注意力的“编码器-解码器”网络 . 论文： . Sequence to Sequence Learning with Neural Networks . | Neural Machine Translation by Jointly Learning to Align and Translate . | . 实现： . Seq2Seq with Attention in PyTorch . | Seq2Seq with Attention in TensorFlow . | . . 深度学习最令人印象深刻的成果大多集中在由卷积神经网络驱动的视觉相关的任务。尽管NLP社区已经使用了LSTM和编码器-解码器结构，在语言模型和翻译上取得了成功，但直到注意力机制的出现，该领域开始表现得出奇地好。 . 当处理语言时，每个符号（如字母、单词、符号），会被输入到循环网络（如LSTM）中，并保留先前输入的部分记忆。换句话说，一个句子就像一段时序序列，而每个符号就是一个时步。这些循环模型通常很难解决时间间隔长的依赖关系。当处理一段序列时，它们容易“忘记”早期的输入，因为梯度需要传递很多个时步。因此通过梯度优化这些模型很困难。 . 新的注意力机制会减轻这种问题。它为网络引入一种“快捷连接”（shortcut connections）的选择，自适应地反馈到早期的时步中。这些连接允许网络在作输出时决定哪些输入是重要的。最典型的例子就是翻译：每当输出一个单词，它通常都对应到一个或多个特定的输入单词。 . 2014 - Adam优化器 . 论文： . Adam: A Method for Stochastic Optimization | . 实现： . Implementing Adam in Python . | PyTorch Adam implementation . | TensorFlow Adam implementation . | . . 神经网络是使用优化器，通过最小化损失函数（如平均分类误差）来训练的。优化器负责调整网络的参数，使网络学习达到目标。大部分优化器都是基于随机梯度下降（SGD）的各种变种。然而这些优化器本身都包含了比如学习率的可调参数。设置合理不仅可以减少训练时间，还能将结果收敛到一个更好的局部最优点。 . 大型研究院通常通过高成本的超参数搜寻算法，伴随着复杂的学习率调度器，来找出简单但对超参数敏感的优化器（比如SGD）中最好的一个。即使有时候效果确实会超过现有基准，但是通过大量的资金“砸”出来的。这种细节一般在学术论文中忽略不提，因此对于那些预算没那么足的研究者会无法优化他们的优化器，从而陷入糟糕的结果中。 . Adam优化器主张用梯度的一阶矩和二阶矩来自动调整学习率。调整后的结果具有较好的鲁棒性，且对超参数的选择不那么敏感。换言之，Adam不需要像其他优化器那样大费周章地进行调整即可使用。尽管“完全体”的SGD效果会更好，Adam让研究更加通畅，因为如果出了问题，首先可以先排除优化器的锅。 . 2014/2015 - 生成对抗网络（GANs） . 论文： . Generative Adversarial Networks . | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks . | . 实现： . DCGAN in PyTorch . | DCGAN in TensorFlow . | . . 生成模型（比如变分自编器）的目标，是生成仿真的数据样本，比如那些好像在哪里见过的人脸图片。GANs这类网络需要对整个数据分布（想象有多少像素）进行建模模拟，而不是像判别器那样只分类成狗或猫。 . GANs背后的基本思想是先后训练两个网络：生成器和判别器。生成器的目标是生成能欺骗识别器的样本，而判别器经过训练，可以区分真图片和生成图片。一段时间过后，识别器会越来越擅长识别假图片，而生成器也会越来越擅长生成欺骗识别器的图片，图片看起来也会越来越真实。早期的GAN只能生成模糊的低分辨率图片，而且训练很不稳定。但随着时间推移，变种和改良版（如DCGAN，Wasserstein GAN，CycleGAN，StyleGAN等）能够生成高分辨率的真实图片和视频。 . 2015 - 残差网络（ResNet） . 论文： . Deep Residual Learning for Image Recognition | . 实现： . ResNet in PyTorch . | ResNet in Tensorflow . | . . 研究人员一直在AlexNet这个突破之上挖掘更好的卷积神经网络（如VGGNet，Inception等）。ResNet就是这一系列快速发展的下一代。时至今日，ResNet的变体仍在各种任务和建立复杂结构中作为基准模型被应用。 . 除了在ILSVRC 2015分类挑战中获得优胜，ResNet的独特之处在于它与其它网络明显不同的深度。论文中最深的网络有1000层，在基准测试中表现得还不错，尽管比起对应的101层和152层网络还是略逊一筹。由于梯度消失的存在，训练这么深的网络是一个具有挑战性的优化问题，序列模型也会有这样的问题。很少研究者相信训练这么深的网络会有优秀且稳定的效果。 . ResNet应用了恒等捷径连接（identity shortcut connections），来帮助梯度传递。解释这些连接的一种说法是ResNet只需要学习两层之间的增量而不是完整的变换，这就显得简单很多。受LSTM的门机制的启发，这种恒定连接也是高速网络（Highway Networks）的一种特例。 . 2017 - Transformers . 论文： . Attention is All You Need | . 实现： . PyTorch: Sequence-to-Sequence Modeling with nn.Transformer and TorchText . | Tensorflow: Transformer model for language understanding . | HuggingFace Transformers Library . | . . 带上面提到过的注意力机制序列对序列（Sequence-to-Sequence）模型表现不错，但由于需要序列计算的循环特性，还是存在一些瑕疵：难以并行，因为每次只处理一个输入。每个时步都依赖上一个时步，这就使得把时步扩展成很长的序列很困难。即使用上注意力机制，这些模型仍会困在分析这些长期依赖的复杂性上。大部分“工作”似乎是在循环层里完成的。 . Transformers模型通过用多个前馈自注意层（feed-forward self-attention layers）完全代替循环层，并行处理所有输入，并在输入和输出之间生成相对较短（相当于更容易优化梯度下降）的路径，来解决这些问题。这使得模型训练得更快、容易扩展，以及能够处理更多数据。为了让网络了解输入的顺序（这在循环网络里是隐式的），Transformers模型使用位置编码，想要知道Transformers到底是如何运作的，建议看这份指南 . 要说Transformers模型表现比所有人预期要好，都算低估了Transformers。接下来几年，它将成为今天大多数NLP和其他序列任务的标准构架，甚至还影响到计算机视觉的构架中。 . 2018 - BERT 和微调的NLP模型 . 论文： . BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | . 实现： . Fine-Tuning BERT with HuggingFace | . . 预训练是指训练一个模型来完成某个任务，然后用经过学习的参数来初始化模型，再经过学习来完成其他有关联的任务。直观来说就是，一个已经学会分辨猫和狗的模型，也会学习到一些关于图像以及毛茸茸的动物的基本知识。当这个模型微调成可分类狐狸，人们会期望他比从头学习的模型表现要好。同样地，一个学会从一个句子中预测下一个词的模型，应该也学到了一些人类语言模式的基本知识。人们会期望它成为一些相关工作（如翻译、情感分析）的良好初始。 . 预训练和微调已经在CV和NLP顺利应用，但一直依赖都是视觉领域的标准，使得在NLP中用好会更具有挑战性。大多目前表现最优（SOTA，state-of-the-art）的成果仍来自完全监督模型。随着Transformers模型的出现，研究者终于开始预训练的工作，研究出ELMo、ULMFiT和OpenAI的GPT。 . BERT是同类发展的最新产物，甚至可以认为它开启了NLP的新纪元。与其他模型一样在预测单词上预学习不同，它在预测句子中哪些单词会被故意去除以及两个句子之间是否存在联系，这些事情上预训练。注意这些任务不需要标注的数据，它可以在任何文本上训练。预训练模型可能学到一些一般的语言属性，就可以进行微调进而解决监督问题（如问答系统、情感预测）。BERT在各种任务都表现得惊人地好，像HuggingFace这样的公司提供了下载，并微调了类BERT模型来解决NLP任务。到目前为止，BERT发展了如XLNet、RoBERTa和ALBERT等变体。 . 2019/2020及以后 - 大型语言模型、自监督学习？ . 《苦痛的教训》一文中清晰地描述了深度学习的历史趋势。算法的并行化（更多的数据）和更多的模型参数，一次又一次地战胜了“聪明的技术”。当OpenAI的GPT-3，一个1750亿参数的普通架构语言模型，只需普通地训练展现出出乎意料地泛化能力时，这个趋势似乎会在2020年继续下去。 . 具有同样趋势的还有对比性自监督学习（contrastive self-supervised learning），比如SimCLR，可以更好地利用未标注的数据。随着模型越来越大和训练得越来越快，能够在网络上高效使用大量未标注数据的技术和学习通用知识的迁移学习系统会变得有价值且广泛采用。 . 这里还有…… . 如果你觉得论文不够看： . Distributed Representations of Words and Phrases and their Compositionality (2013) . | Speech recognition with deep recurrent neural networks (2013) . | Very Deep Convolutional Networks for Large-Scale Image Recognition (2014) . | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (2015) . | Rethinking the Inception Architecture for Computer Vision (2015) . | WaveNet: A Generative Model for Raw Audio (2016) . | Mastering the game of Go with deep neural networks and tree search (2016) . | Neural Architecture Search with Reinforcement Learning (2017) . | Mask R-CNN (2017) . | Dota 2 with Large Scale Deep Reinforcement Learning (2017-2019) . | The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018) . | EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (2019) . | .",
            "url": "https://bjchacha.github.io/myblog/translations/deeplearning/2020/08/13/trans-a-brief-historical-review-of-deep-learning.html",
            "relUrl": "/translations/deeplearning/2020/08/13/trans-a-brief-historical-review-of-deep-learning.html",
            "date": " • Aug 13, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "在网页中应用实时MNIST识别",
            "content": "&#21069;&#35328; . 偶然发现一个包Gradio，可以快速构建基于机器学习应用的Web交互接口。这里尝试能否使用在Fastpages的Jupyter Notebook文章中。 . 这里直接应用官网的demo之一——实时识别手写数字。 . &#19978;&#25163; . 先训练一个MNIST分类器。 | import tensorflow as tf import gradio as gr (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() x_train = x_train.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. x_test = x_test.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. # Lenet 5 model = tf.keras.Sequential([ tf.keras.layers.Conv2D(filters=6, kernel_size=5, padding=&#39;same&#39;, activation=&#39;relu&#39;, input_shape=(28, 28, 1)), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation=&#39;relu&#39;), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Conv2D(filters=120, kernel_size=5, activation=&#39;relu&#39;), tf.keras.layers.Flatten(), tf.keras.layers.Dense(84, activation=&#39;relu&#39;), tf.keras.layers.Dense(10, activation=&#39;softmax&#39;), ]) model.compile(optimizer=&#39;adam&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, verbose=0) . 构建Gradio界面 | # gradio interface need 3 parameters：predict function、input &amp; output components # predict function def classify(image): image = image.reshape(-1, 28, 28, 1) prediction = model.predict(image).tolist()[0] return {str(i): prediction[i] for i in range(10)} # input component sketchpad = gr.inputs.Sketchpad() # output components label = gr.outputs.Label(num_top_classes=3) # generate the UI # live=True: reload changes automatically # capture_sessiong=True: specifically for tensorflow 1.0 interface = gr.Interface(classify, sketchpad, label, live=True, capture_session=True) interface.launch() . WARNING:tensorflow:From C: Users bjcha anaconda3 envs directml lib site-packages gradio interface.py:118: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead. WARNING:tensorflow:From C: Users bjcha anaconda3 envs directml lib site-packages gradio interface.py:119: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead. Running locally at: http://127.0.0.1:7860/ . (&lt;gradio.networking.serve_files_in_background.&lt;locals&gt;.HTTPServer at 0x183c468db08&gt;, &#39;http://127.0.0.1:7860/&#39;, None) . &#32467;&#26524; . 功能都正常实现出来了，虽然识别准确率感人，但关我们主角Gradio什么事。 . 但是Gradio文档展现的api确实有点少，比如本例中UI显示范围受到限制，想要调整UI大小却找不到相应的参数。总的来说Gradio更偏向傻瓜式，应用起来确实快捷简单。 . 优点： . 方便快捷 | . | 缺点： . api较少，可定义幅度小 | . | .",
            "url": "https://bjchacha.github.io/myblog/tensorflow/gradio/2020/07/30/MNIST-web-app.html",
            "relUrl": "/tensorflow/gradio/2020/07/30/MNIST-web-app.html",
            "date": " • Jul 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "使用DirectML进行GPU模型训练",
            "content": "&#20851;&#20110;DirectML . 详情看README。主要是支持所有“支持DX12的显卡”进行硬件加速运算。这对于手上只有A卡的我无疑又是个好东西。 . 先前已经写过一篇关于PlaidML的博文，也是可用A卡硬件加速。所以这里省略部分步骤，并最后跟PlaidML比较下效果。 . &#23433;&#35013;DirectML . 目前Tensorflow with DirectML仅支持最新版本的Windows 10和WSL。 . 安装非常简单，直接pip一下就好。这里例行使用conda创建虚拟环境来运行DirectML。 . conda create -n directml python=3.7 conda activate directml pip install tensorflow-directml . . Note: DirectML只支持Tensorflow 1.15. . &#20351;&#29992;DirectML&#35757;&#32451;Fashion-MNIST&#20998;&#31867;&#22120; . 这里跑跟之前试用PlaidML时一样的代码，方便对比。 . #collapse import tensorflow as tf from time import time data = tf.keras.datasets.fashion_mnist (x_train, y_train), (x_test, y_test) = data.load_data() x_train = x_train.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. x_test = x_test.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. # print(x_train.shape) model = tf.keras.Sequential([ tf.keras.layers.Conv2D( filters=64, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39;, input_shape=(28, 28, 1) ), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Dropout(0.3), tf.keras.layers.Conv2D( filters=32, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39; ), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Dropout(0.3), tf.keras.layers.Flatten(), tf.keras.layers.Dense(units=256, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.5), tf.keras.layers.Dense(units=10, activation=&#39;softmax&#39;)]) model.compile( optimizer=&#39;adam&#39;, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) train_start = time() model.fit(x_train, y_train, batch_size=64, epochs=10) train_end = time() _, accuracy = model.evaluate(x_test, y_test) print(&#39;training time cost: {0:.1f} s, accuracy: {1:.4f}&#39;.format(train_end-train_start, accuracy)) . . WARNING:tensorflow:From C: Users bjcha Anaconda3 envs directml lib site-packages tensorflow_core python ops resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Train on 60000 samples Epoch 1/10 60000/60000 [==============================] - 14s 226us/sample - loss: 0.5786 - acc: 0.7869 Epoch 2/10 60000/60000 [==============================] - 13s 214us/sample - loss: 0.4072 - acc: 0.8522 Epoch 3/10 60000/60000 [==============================] - 13s 213us/sample - loss: 0.3625 - acc: 0.8681 Epoch 4/10 60000/60000 [==============================] - 13s 216us/sample - loss: 0.3340 - acc: 0.8788 Epoch 5/10 60000/60000 [==============================] - 13s 213us/sample - loss: 0.3179 - acc: 0.8842 Epoch 6/10 60000/60000 [==============================] - 13s 218us/sample - loss: 0.3003 - acc: 0.8903 Epoch 7/10 60000/60000 [==============================] - 13s 213us/sample - loss: 0.2891 - acc: 0.8933 Epoch 8/10 60000/60000 [==============================] - 13s 213us/sample - loss: 0.2768 - acc: 0.8980 Epoch 9/10 60000/60000 [==============================] - 13s 211us/sample - loss: 0.2704 - acc: 0.9011 Epoch 10/10 60000/60000 [==============================] - 13s 212us/sample - loss: 0.2586 - acc: 0.9046 10000/10000 [==============================] - 1s 87us/sample - loss: 0.2360 - acc: 0.9130 training time cost: 129.5 s, accuracy: 0.9130 . 上面可以看到DirectML可以正常使用A卡进行训练，训练时长为129秒，而PlaidML跑了124秒。 虽说DirectML比PLaidML慢，但胜在支持所有DX12的显卡以及完整的Tensorflow（PlaidML只支持Keras）。 .",
            "url": "https://bjchacha.github.io/myblog/tensorflow/directml/2020/06/21/using-directml-tensorflow-to-ai.html",
            "relUrl": "/tensorflow/directml/2020/06/21/using-directml-tensorflow-to-ai.html",
            "date": " • Jun 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "在WSL中安装MacOS虚拟机",
            "content": "0. 前言 . 在github上发现有大佬做了个脚本，可以傻瓜式创建MacOS虚拟机。一直很佩服这些做这种便捷易懂的教程的作者，真的希望自己也有能力做这些事情。 . 1. 环境 . WSL (Ubuntu) | VirtualBox 6.1.6 or higher with Extension Pack | . 2. 进入WSL . 打开Ubuntu终端，首先安装必要的依赖项: sudo apt-get install coreutils gzip unzip xxd wget sudo apt-get update -y sudo apt-get install dmg2img . | 下载大佬的脚本，并在Ubuntu终端中运行。 WSL的默认路径是Windows下的用户文件夹，如C: Users username，cd几下就能定位到Windows的文件。 . 另外提示一下，建议硬盘可用容量50G左右。 . | 跟着大佬的脚本的提示一步步走。一定要看脚本提示，因为进入安装界面后还是需要脚本的自动化操作。期间虚拟机会重启几次，等待脚本完全结束后就可以自己操作了。 | 3. 凑数用 .",
            "url": "https://bjchacha.github.io/myblog/wsl/2020/05/27/MacOS-in-WSL.html",
            "relUrl": "/wsl/2020/05/27/MacOS-in-WSL.html",
            "date": " • May 27, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "[动态规划]0-1背包问题",
            "content": "1. 问题描述 . 给定一个可承重W的背包和N个物品，其中第i个物品的重量为wt[i]，价值为val[i]。求背包可承载物品的最大价值。 | 示例： 输入：W = 4, N = 3, wt = [2, 1, 3], val = [4, 2, 3] | 输出：6 | 解释：装进背包的物品为[0, 1]，重量为wt[0]+wt[1]=3&lt;W=4，价值为val[0]+val[1]=6。 | . | . 2. 思路 . 每次放入第i个物品，然后求W-wt[i]的01背包问题，不难看出这是一道非常典型的动态规划问题。接下来就是怎么遍历的问题。 0-1背包问题的一个特点，就是物品的状态只有两个：放进背包和不放进背包（这也是0-1的由来），故可以先对物品堆进行遍历，防止重复放入同一物品；然后每一个物品中，对每一个有效背包状态进行遍历。即这里有两层遍历： . for item in items: for stage in stages: try to put item in stage . 这里的“有效背包状态”是什么意思？举个例子，我们第一次向背包放入一个重量为2的物品，那么对于下一个物品来说，有效背包状态为[0,2]，即不放入第一个物品时背包的负载，以及放入第一个物品时背包的负载。1不是有效的背包状态，因为之前没有遍历过重量为1的物品。 另外，每一个背包状态都是以最大价值进行记录，所以可以用一个集合set来记录有效背包状态，比如set[4]=5表示背包负载为4时可承载物品的最大价值为5。自然，最后答案就是所有状态中的最大值。 . 3. 代码 . 上面对这次动态规划两层遍历的逻辑就理得差不多了，代码： . def zero_one_knapsack(w, n, wt, val): dp = [0 for _ in range(w+1)] # 每个容量记录其最大容纳价值 storage = set([0]) # 记录可放入物品的有效背包状态 for j in range(n): # 遍历每个物品 for i in list(storage): # 遍历每个有效背包状态 if i + wt[j] &lt;= w: # 若背包可容纳该物品 dp[i + wt[j]] = max(dp[i + wt[j]], dp[i] + val[j]) storage.add(i + wt[j]) return max(dp) . 4. 总结 . 确定主次遍历 | 理清背包状态 | .",
            "url": "https://bjchacha.github.io/myblog/algorithm/2020/03/20/algorithm-dp-0-1-knapsack.html",
            "relUrl": "/algorithm/2020/03/20/algorithm-dp-0-1-knapsack.html",
            "date": " • Mar 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "[动态规划]编辑距离问题",
            "content": "0. 前言 . 好久没刷leetcode了，加上要准备考研复试，所以决定尝试开个算法系列，每篇解决一道比较经典或者稍有难度的算法题，注重从思路到代码、从无到有的过程。 其实之前有写一篇类似的刷题总结文章，但只写了题目和代码答案，没有记录思路过程，导致回忆的时候十分痛苦。而且leetcode的答案网上一搜一大把，那篇文章没啥意义，所以决定关掉并重开这个系列。 在这里建议不要一卡住就看答案，很多问题卡个一两天很正常。但自己亲手解决每一道算法题真的会带来很大的成就感，这种正反馈也是后续刷题的重要精神源泉。在这里顺便贴一个我觉得不错的学习参考：labuladong的算法小抄。 这是开篇之作，所以废话很多（skr~）马上进入本文主题——一道颇有难度的动规1问题：编辑距离问题（72. Edit Distance）。 . 1. 问题描述 . 给定两个字符串s1和s2，计算出将s1转换成s2所使用的最少操作数。 | 你可以对一个字符串进行以下三种操作： 插入一个字符 | 删除一个字符 | 替换一个字符 | . | 示例1： 输入：s1 = “horse”, s2 = “ros” | 输出：3 | 解释： horse -&gt; rorse （将’h’替换为’r’） | rorse -&gt; rose （删除’r’） | rose -&gt; ros （删除’e’） | . | . | 示例2： 输入：s1 = “intention”, s2 = “execution” | 输出：5 | 解释： intention -&gt; inention （删除’t’） | inention -&gt; enention （将’i’替换为’e’） | enention -&gt; exention （将’n’替换为’x’） | exention -&gt; exection （将’n’替换为’c’） | exection -&gt; exection （插入’u’） | . | . | . 2. 思路 . 动态规划是一个好算法，它适合解决求最值的优化问题，尤其是对于那些不能很直观地得出方法的问题，第一反应就是考虑用动态规划。动态规划易于实现，只要处理好分支条件和边界条件，往往就能得出结果。 但不是所有问题都适用于动态规划。使用动态规划有一个条件，就是问题必须符合最优子结构，即子问题的最优解必须是问题最优解的子集。比如求全级最高分，可以通过求每班最高分，再从中选最高分。但求全级最大分差就不能这么做了，因为最高分和最低分不一定在同一个班。 动态规划就是把问题通过递归把问题不断拆分成子问题来求解。显然子问题的优化难度更小，因此递归实质上就是递归，但实现的手段不一定是递归，常见的有dp表等。 . 3. 代码 . 回到问题本身，处理两个字符串一般用两个指针各自遍历，这里我们从字符串尾部开始，下面先给出遍历过程的伪代码： . i = len(s1) - 1, j = len(s2) - 1 for i, j to 0: if s1[i] == s2[j]: skip # 若字符相同，则不做任何操作 else: insert, delect or replace # 若字符不相同，则从三种操作中选一 . 这就是动态规划的整体框架，而当中关键就在于“三种操作中选一”。下面我们来讨论一下如何处理这个分支。 . 插入： 在i指针处插入一个字符后，i指针指向新插入的字符，即i=i+1，j不变。 | 删除： 在i指针处删除一个字符后，i指针指向前继字符，即i=i-1，j不变。 | 替换： 在i指针处替换一个字符后，i，j位置均不变。 剩下还有两种边界需要处理，很简单： | i指针先遍历完： 此时说明s1是s2的后置子串，因此只需把s2余下字符插入到s1前面即可。 | j指针先遍历完： 此时说明s2是s1的后置子串，因此只需要把s1前面的字符删除即可。 | . 现在分支逻辑都理清楚了，可以从上面框架中填充条件。 . def edit_distance(s1, s2): def dp(i, j): if i &lt; 0: return j + 1 # 插入s2余下字符 elif j &lt; 0: return i + 1 # 删除s1余下字符 elif s1[i] == s2[j]: return dp(i-1, j-1) # 跳过 else: return min( dp(i-1, j) + 1, # 删除 dp(i, j-1) + 1, # 插入 dp(i-1, j-1) + 1 # 替换 ) return dp(len(s1) - 1, len(s2) - 1) . 到这里上面这段代码已经可以正确求解了，但如果把上面的代码一般是不能通过的，因为太暴力了。 我们来估算一下时间复杂度：如果每次都执行最后一个分支的话，即每次执行都最多调用自己三次，那么整个执行结构就是一个三叉树。树的高度取决于字符串的长度。而一个高度为h的三叉数最多有$ frac{3^h-1}{2}$个节点，故$O(n)=3^n$。这个时间复杂度就非常夸张了，所以接下来要想办法优化我们的算法。 . 优化 . 不作优化的动态规划一般会有很严重的冗余。比如这一题中dp(i-1,j) -&gt;dp(i,j-1)跟dp(i-1,j-1)重复了，即dp(i-1,j-1)的值被求了两次。一旦发现出现路线的重叠，那么整个算法就会有大量的重复调用，非常暴力。 动态规划的优化就是去冗余，也就是给上面那棵三叉树剪枝。最常见就是用备忘录去记录每个节点是否被访问过，或者直接用dp表直接在数组上操作。 这里我们在原来的基础上加上备忘录。这里操作的主体有两个：指针i和j，因此备忘录是个二维数组memo[i][j]。遍历的最长长度就二维数组的大小，故$O(n)=len(s1)*len(s2)$。最后代码如下。 . def edit_distance(s1, s2): max_len = max(len(s1), len(s2)) memo = [[max_len for _ in range(len(s2) + 1)] for _ in range(len(s1) + 1)] def dp(i, j): if i == 0: memo[i][j] = j elif j == 0: memo[i][j] = i elif s1[i-1] == s2[j-1]: memo[i][j] = memo[i-1][j-1] if memo[i-1][j-1] &lt; max_len else dp(i - 1, j - 1) # skip else: d1 = memo[i-1][j] + 1 if memo[i-1][j] &lt; max_len else dp(i-1, j) + 1 d2 = memo[i][j-1] + 1 if memo[i][j-1] &lt; max_len else dp(i, j-1) + 1 d3 = memo[i-1][j-1] + 1 if memo[i-1][j-1] &lt; max_len else dp(i-1, j-1) + 1 memo[i][j] = min(d1, d2, d3) return memo[i][j] return dp(len(s1), len(s2)) . 总结 . 动态规划适合符合最优子结构的最优化问题求解； | 动态规划可以使用递归或dp表实现，递归简单直观，dp表比较复杂但执行快。 | 快速写出循环体，简单呈现整体框架； | 动态规划使用递归时需要用备忘录memo进行优化。 | 引用 . 即动态规划啦（其实是想test一下fastpages的引用功能 &#8617; . |",
            "url": "https://bjchacha.github.io/myblog/algorithm/2020/03/17/algorithm-dp-edit-distance.html",
            "relUrl": "/algorithm/2020/03/17/algorithm-dp-edit-distance.html",
            "date": " • Mar 17, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "使用PlaidML进行GPU模型训练",
            "content": "&#20851;&#20110;PlaidML . PlaidML是Intel的一个AI开发工具，目前支持Keras, ONNX,nGraph。 现在大火的Tensorflow和PyTorch只支持Nvidia的CUDA进行GPU加速计算。 而PlaidML可使用OpenCL进行加速。虽然AMD有自己的加速运算平台ROCm，但目前不支持windows系统，而且OpenCL在速度上貌似还比不上CUDA，对A卡Windows用户（就是我）来说但总比没有的好。 . 本文使用的机器主要配置如下： . E3 1230 v2 | RX 480 | DDR3 1333 4G x2 | . 下面从安装到跑模型，来试试PlaidML的效果如何。 . &#23433;&#35013;PlaidML . 用conda创建一个新环境，在其中使用pip安装PlaidML: . conda create -n plaidml conda activate plaidml pip instal -U plaidml-keras plaidml-setup . 根据提示设置PlaidML。 . &#20351;&#29992;PlaidML&#35757;&#32451;Fashion-MNIST&#20998;&#31867;&#22120; . 首先用tensorflow中的keras跑一下，看看要跑多久。 . #collapse # 使用tensorflow.keras(cpu)训练 import tensorflow as tf from time import time data = tf.keras.datasets.fashion_mnist (x_train, y_train), (x_test, y_test) = data.load_data() x_train = x_train.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. x_test = x_test.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) / 255. # print(x_train.shape) model = tf.keras.Sequential([ tf.keras.layers.Conv2D( filters=64, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39;, input_shape=(28, 28, 1) ), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Dropout(0.3), tf.keras.layers.Conv2D( filters=32, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39; ), tf.keras.layers.MaxPool2D(pool_size=2), tf.keras.layers.Dropout(0.3), tf.keras.layers.Flatten(), tf.keras.layers.Dense(units=256, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.5), tf.keras.layers.Dense(units=10, activation=&#39;softmax&#39;)]) model.compile( optimizer=&#39;adam&#39;, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) train_start = time() model.fit(x_train, y_train, batch_size=64, epochs=10) train_end = time() _, accuracy = model.evaluate(x_test, y_test) print(&#39;training time cost: {0:.1f} s, accuracy: {1:.4f}&#39;.format(train_end-train_start, accuracy)) . . Train on 60000 samples Epoch 1/10 60000/60000 [==============================] - 46s 769us/sample - loss: 0.5855 - accuracy: 0.7840 Epoch 2/10 60000/60000 [==============================] - 46s 758us/sample - loss: 0.4013 - accuracy: 0.8541 Epoch 3/10 60000/60000 [==============================] - 46s 762us/sample - loss: 0.3586 - accuracy: 0.8695 Epoch 4/10 60000/60000 [==============================] - 47s 777us/sample - loss: 0.3357 - accuracy: 0.8769 Epoch 5/10 60000/60000 [==============================] - 47s 778us/sample - loss: 0.3172 - accuracy: 0.8826 Epoch 6/10 60000/60000 [==============================] - 44s 736us/sample - loss: 0.3010 - accuracy: 0.8888 Epoch 7/10 60000/60000 [==============================] - 44s 735us/sample - loss: 0.2867 - accuracy: 0.8940 Epoch 8/10 60000/60000 [==============================] - 44s 736us/sample - loss: 0.2781 - accuracy: 0.8974 Epoch 9/10 60000/60000 [==============================] - 44s 737us/sample - loss: 0.2697 - accuracy: 0.9013 Epoch 10/10 60000/60000 [==============================] - 44s 735us/sample - loss: 0.2631 - accuracy: 0.9033 10000/10000 [==============================] - 2s 201us/sample - loss: 0.2369 - accuracy: 0.9120 training time cost: 451.5 s, accuracy: 0.91 . 现在轮到本文的主角plaidml，展现真正的技术了（不是 . Note: plaidml和tensorflow都有keras，不同的是使用的后端。如果没有使用conda进行环境分隔的话，要将keras的后端切换到plaidml，才能确保plaidml正确运行。 . #collapse_show # 更改keras后端 import plaidml.keras plaidml.keras.install_backend() import os os.environ[&#39;KERAS_BACKEND&#39;] = &#39;plaidml.keras.backend&#39; . . . Tip: 如果不想每次都运行上述代码，可在%USERPROFILE% .keras keras.json配置文件中的&quot;backend&quot;设为 &quot;plaidml.keras.backend&quot;. . #collapse # 使用plaidml.keras(gpu) 训练 import keras from time import time (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data() x_train = x_train.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) x_test = x_test.astype(&#39;float32&#39;).reshape(-1, 28, 28, 1) model = keras.Sequential([ keras.layers.Conv2D( filters=64, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39;, input_shape=(28, 28, 1) ), keras.layers.MaxPool2D(pool_size=2), keras.layers.Dropout(0.3), keras.layers.Conv2D( filters=32, kernel_size=2, padding=&#39;same&#39;, activation=&#39;relu&#39; ), keras.layers.MaxPool2D(pool_size=2), keras.layers.Dropout(0.3), keras.layers.Flatten(), keras.layers.Dense(units=256, activation=&#39;relu&#39;), keras.layers.Dropout(0.5), keras.layers.Dense(units=10, activation=&#39;softmax&#39;)]) model.compile( optimizer=&#39;adam&#39;, loss=keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) train_start = time() model.fit(x_train, y_train, batch_size=64, epochs=10) train_end = time() _, accuracy = model.evaluate(x_test, y_test) print(&#39;training time cost: {0:.1f} s, accuracy: {1}&#39;.format(train_end-train_start, accuracy)) . . Using plaidml.keras.backend backend. INFO:plaidml:Opening device &#34;opencl_amd_ellesmere.0&#34; Epoch 1/10 60000/60000 [==============================] - 22s 374us/step - loss: 1.1562 - acc: 0.7010 Epoch 2/10 60000/60000 [==============================] - 12s 193us/step - loss: 0.5358 - acc: 0.8014 Epoch 3/10 60000/60000 [==============================] - 12s 195us/step - loss: 0.4548 - acc: 0.8316 Epoch 4/10 60000/60000 [==============================] - 12s 197us/step - loss: 0.4207 - acc: 0.8457 Epoch 5/10 60000/60000 [==============================] - 11s 185us/step - loss: 0.3989 - acc: 0.8551 Epoch 6/10 60000/60000 [==============================] - 11s 186us/step - loss: 0.3773 - acc: 0.8625 Epoch 7/10 60000/60000 [==============================] - 11s 185us/step - loss: 0.3664 - acc: 0.8651 Epoch 8/10 60000/60000 [==============================] - 11s 187us/step - loss: 0.3551 - acc: 0.8713 Epoch 9/10 60000/60000 [==============================] - 11s 184us/step - loss: 0.3425 - acc: 0.8758 Epoch 10/10 60000/60000 [==============================] - 11s 183us/step - loss: 0.3355 - acc: 0.8763 10000/10000 [==============================] - 5s 473us/step training time cost: 124.2 s, accuracy: 0.8858 . 通过上面两次训练对比看到，CPU训练需要451秒，而通过PlaidML使用GPU训练则只需124秒，大概缩短了2/3的时间，效果还是很明显的。 综上，PlaidML适合没有N卡但坚守Windows，以及MacBook Pro的用户。但有条件还是搞一台N卡主机吧， . &#30058;&#22806;&#65306;&#20026;&#20160;&#20040;&#19981;&#38382;&#38382;&#31070;&#22855;&#30340;Colab&#21602;&#65311; . 不试不知道，试了才知道。上面代码在使用了GPU的Colab下跑，结果输出： . training time cost:50.0 s, accuracy: 0.9147 . 最后知道真相的我眼泪流下来，手上PlaidML突然就不香了。 .",
            "url": "https://bjchacha.github.io/myblog/keras/plaidml/2020/02/25/using-plaidml-keras-to-ai.html",
            "relUrl": "/keras/plaidml/2020/02/25/using-plaidml-keras-to-ai.html",
            "date": " • Feb 25, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "VSCode用于cpp调试的相关设置",
            "content": "0. 前言 . 由于对Cpp的需求比较轻量，用来学习语法和写写算法题之类的，用visual studio觉得十分臃肿。vscode是一款非常优秀的代码编辑器，本身不具备任何编译器等IDE功能。需要进行一定的环境准备才能用vscode进行Cpp代码的编译和调试。 . 1. GCC编译器安装 . 1.下载MinGW-w64，选择最新版本的x86_64-posix-seh。 2.解压下载下来的压缩包，并将mingw64文件夹移动到C盘根目录下（当然也可以到其他地方）。 3.将mingw64文件夹下的bin文件夹目录添加到用户环境变量中的PATH中。此例中则将C: mingw64 bin添加到PATH中。 4.验证gcc编译器安装是否成功：Win+R运行cmd，输入gcc，若提示 . gcc:fatal error: no input files . 则gcc编译器安装成功；若提示： . 不是内部命令或外部命令 . 则gcc没有安装成功，回头检查环境变量中PATH中的目录与gcc实际目录是否符合。 . 2. vscode cpp相关插件 . C/C++：提供Cpp Debug等功能。 | . 3. vscode 相关配置文件 . 在vscode打开Cpp工作区后，会在当前目录下自动生成.vscode文件夹。该文件夹下存放当前工作区的以下配置文件。若无以下文件可自行创建。 . launch.json . { &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;${fileDirname}/${fileBasenameNoExtension}.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;${workspaceFolder}&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true, &quot;internalConsoleOptions&quot;: &quot;neverOpen&quot;, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;miDebuggerPath&quot;: &quot;gdb.exe&quot;, &quot;setupCommands&quot;: [ { &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: false } ], &quot;preLaunchTask&quot;: &quot;Compile&quot;, } ] } . | tasks.json . { &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;label&quot;: &quot;Compile&quot;, &quot;command&quot;: &quot;g++&quot;, &quot;args&quot;: [ &quot;${file}&quot;, &quot;-o&quot;, &quot;${fileDirname}/${fileBasenameNoExtension}.exe&quot;, &quot;-g&quot;, &quot;-Wall&quot;, &quot;-static-libgcc&quot;, &quot;-fexec-charset=GBK&quot; ], &quot;type&quot;: &quot;process&quot;, &quot;group&quot;: { &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true }, &quot;presentation&quot;: { &quot;echo&quot;: true, &quot;reveal&quot;: &quot;always&quot;, &quot;focus&quot;: false, &quot;panel&quot;: &quot;shared&quot;, }, } ] } . | setting.json (部分) . { ... &quot;files.defaultLanguage&quot;: &quot;cpp&quot;, &quot;editor.formatOnType&quot;: true, &quot;editor.suggest.snippetsPreventQuickSuggestions&quot;: false, &quot;editor.acceptSuggestionOnEnter&quot;: &quot;off&quot;, &quot;editor.snippetSuggestions&quot;: &quot;top&quot;, &quot;code-runner.runInTerminal&quot;: true, &quot;code-runner.executorMap&quot;: { &quot;c&quot;: &quot;cd $dir &amp;&amp; gcc &#39;$fileName&#39; -o &#39;$fileNameWithoutExt.exe&#39; -Wall -g -O2 -static-libgcc -std=c11 -fexec-charset=GBK &amp;&amp; &amp;&#39;$dir$fileNameWithoutExt&#39;&quot;, &quot;cpp&quot;: &quot;cd $dir &amp;&amp; g++ &#39;$fileName&#39; -o &#39;$fileNameWithoutExt.exe&#39; -Wall -g -O2 -static-libgcc -std=c++17 -fexec-charset=GBK &amp;&amp; &amp;&#39;$dir$fileNameWithoutExt&#39;&quot; }, &quot;code-runner.saveFileBeforeRun&quot;: true, &quot;code-runner.preserveFocus&quot;: true, &quot;code-runner.clearPreviousOutput&quot;: false, &quot;code-runner.ignoreSelection&quot;: true, &quot;C_Cpp.clang_format_sortIncludes&quot;: true, ... } . | . 4. 用vscode进行cpp调试 . 1.在任意目录下创建文件夹cpp。 2.在vscode下Ctrl+K、Ctrl+O，打开cpp文件夹。 3.Ctrl+N创建新文件，随便写个cpp demo: . #include &lt;iostream&gt; using namespace std; int main() { cout &lt;&lt; &quot;hello world&quot; &lt;&lt; endl; int a; cin &gt;&gt; a; return 0; } . 4.Shift+Ctrl+B进行编译；F5进行调试，会弹出命令行窗口显示hello world输出。至此完成所有设置。 . 参考 . 知乎 vscode官方文档 .",
            "url": "https://bjchacha.github.io/myblog/vscode/cpp/2020/01/28/vscode-cpp-setting.html",
            "relUrl": "/vscode/cpp/2020/01/28/vscode-cpp-setting.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "精灵宝可梦 动画观看顺序",
            "content": "前言 . 自用，不包括特别篇和其他小剧场。 | 没看过漫画的强烈推荐特别篇。 | 摘自知乎，本文也会不定期更新。 | . . 无印篇（EP,OP） . 石英联盟： 001（神奇宝贝，就决定是你了！）——054（警犬卡蒂狗） | 剧场版：精灵宝可梦：超梦的逆袭 | 055（按快门的机会是皮卡丘）——080（神奇宝贝联盟最后的战斗） | . | 橘子群岛： 081（真新镇，新的开始）——104（皮卡丘对抗喵喵） | 剧场版：精灵宝可梦：梦幻之宝可梦 洛奇亚爆诞 | 105（喷火龙，就决定是你了！）——116（宿敌大对决，小茂对抗小智） | . | 城都联盟： 117（若叶镇，吹起开启之风的城镇）——155（圈圈熊，吓死人） | 剧场版：精灵宝可梦：结晶塔的帝王 | 156（麒麟奇，超能力神奇宝贝之村）——205（变隐龙在哪里？看不见的神奇宝贝，大混乱！） | 剧场版：精灵宝可梦：雪拉比 穿梭时空的相遇 | 206（讨厌水系神奇宝贝的乔伊！小霞的愤怒！）——256（龙宫道馆，在水中战斗） | 剧场版：精灵宝可梦：水都的守护神 拉帝亚斯与拉帝欧斯 | 257（乘龙之歌！）——274（与皮卡丘分手） | . | . . 超世代（AG） . 丰缘联盟： 001（新的大地！新的冒险！！）——034（最初拿到的宝可梦，大混乱！） | 剧场版：精灵宝可梦：七夜的许愿星 基拉祈 | 035（小遥！初次挑战宝可梦华丽大赛！）——085（茵郁道馆！天空之战！） | 剧场版：精灵宝可梦：裂空的访问者 代欧奇希斯 | 086（喷火驼载着电影来！）——134（月见山！皮宝宝与皮皮与皮可西！） | 剧场版：精灵宝可梦：梦幻与波导的勇者 路卡利欧 | . | 对战开拓区： 135（初阵！对战工厂！！（前篇））——183（长尾怪手与国王！） | 剧场版：精灵宝可梦：宝可梦保育家与苍海的王子 玛纳霏 | 184（聒噪鸟与宝可梦相声！）——192（旅程的终点，以及旅程的开始！） | . | . . 钻石与珍珠：神奥联盟（DP） . 001（出发！双叶镇到真砂镇！）——039（皮卡丘留守记！） | 剧场版：精灵宝可梦：决战时空之塔 帝牙卢卡VS帕路奇犽VS达克莱伊 | 040（冠军·竹兰登场！）——086（缘之时装大会！通往宝可梦风格设计师之路！！） | 剧场版：精灵宝可梦：骑拉帝纳与冰空的花束 洁咪 | 087（路霸可达鸭！）——135（全员参战！宝可梦大胜利！！） | 剧场版：精灵宝可梦：阿尔宙斯 超克的时空 | 136（天冠山的遗迹！银河队的阴谋！！）——183（开幕！神奥联盟・铃兰大会！！） | 剧场版：精灵宝可梦：幻影的霸者 索罗亚克 | 184（神奥联盟第三轮！真司对阿驯！！）——191（回忆是珍珠！友情是钻石！！） | . . 超级愿望（BW） . 合众联盟： 001（前往合众地方！捷克罗姆的身影！！）——039（全体集合！东·乔治对战！！） | 剧场版：精灵宝可梦：比克提尼与黑英雄 捷克罗姆 | 剧场版：精灵宝可梦：比克提尼与白英雄 雷希拉姆 | 040（激战东·乔治对战！藤藤蛇VS驹刀小兵！！）——084（激战立涌道馆！VS霍米加！！（后篇）） | . | 东合众： 085（歌唱吧，美洛耶塔！爱的旋律！！）——087（大岩蛇岛野外求生！！） | 剧场版：精灵宝可梦：酋雷姆VS圣剑士 凯路迪欧 | 088（酒侍侦探天桐！消失的喷嚏熊之谜！！）——108（决战合众联盟！皮卡丘对路卡利欧！！） | . | N章： 109（红豆杉研究所！展开新旅行！！）——122（莱希拉姆对N！理想和真实的那一方!!） | . | Da！章： 123（再见了合众！新的乘船之旅！！）——133（光之飞碟！大宇怪之城！！） | 剧场版：精灵宝可梦：神速的盖诺赛克特 超梦觉醒 | 134（三色堇登场！伞电蜥与坐骑山羊!!）——144（艾莉丝VS小椿！通往龙系大师之路!!） | . | . . XY系列 . XY 001（抵达卡洛斯地方！梦想与冒险的开始!!）——034（森林拳王！摔角鹰人登场!!） | 剧场版：精灵宝可梦：破坏之茧与蒂安希 | 035（空中对战!?摔角鹰人对烈箭鹰!!）——081（穿越时空的小智！洛托姆的心愿！） | 剧场版：精灵宝可梦：光轮的超魔神 胡帕 | 082（南瓜怪人变装庆典！再见了，南瓜精!?）——093（百刻道馆的双打对战！葛吉花的先知!!） | . | XY&amp;Z 094（Z爆炸诞生！卡洛斯的潜伏者!!）——126（超级蜥蜴王对雷丘！我要学到许多的经验!!） | 剧场版：精灵宝可梦：波尔凯尼恩与机关人偶玛机雅娜 | 127（全面对战的准决赛！小智对翔太!!）——142（最强的二人！希特隆与天桐!!） | . | . . 太阳&amp;月亮 . 001（阿罗拉！最初的岛屿、最初的宝可梦们!!）——033（厉害的池塘霸主弱丁鱼！） | 剧场版：精灵宝可梦:就决定是你了! | 034（火焰对战！嘎啦嘎啦现身!!）——081（阿罗拉新的火焰！皇家小智诞生!!） | 剧场版：精灵宝可梦：大家的物语 | 082（跳舞，跳舞进化吗？）——至今 | 待续…… | .",
            "url": "https://bjchacha.github.io/myblog/anime/2019/07/14/pokemon-best-way-to-watch.html",
            "relUrl": "/anime/2019/07/14/pokemon-best-way-to-watch.html",
            "date": " • Jul 14, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "LeetCode 刷题总结",
            "content": "0. Preface . 刷Leetcode过程中记录所做过题目的答案，偏向归档属性。 | Leetcode许多题目有多种算法解，以下一般只采用其中一种，优先选择runtime较低、复杂程度较低的方案。 | Leetcode的runtime一般情况下并不代表时间复杂度，有许多情况下时间复杂度较高的算法runtime却很低。所以不要本文盲目追求低runtime，理解并熟练运用多种算法来处理问题才是王道。 | . 1. Two Sum . Description: 给定一个int数组，输出其两数之和的最大值。 | . | Analysis: 遍历一次数组，用unordered_map（哈希表）记录每个出现过的值及其索引值。若在表中查找出目标与当前值的差值，则返回两数的索引值。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(n)$ | . | Solution: // Runtime: 8 ms, beats 99.94 % // Memory: 10.2 MB, beats 51.82 % class Solution { public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) { unordered_map&lt;int, int&gt;m; for(auto i = 0; i &lt; nums.size(); ++i){ if(m.count(target - nums[i])) return {m[target - nums[i]], i}; m[nums[i]] = i; } return {}; } }; . | . . 2. Add Two Numbers . Description: 给定两个链表，将两个链表表示的非负整数相加，并输出其链表形式（从低位指向高位）。 | . | Analysis: 由于整数链表由低位指向高位，可以直接同时遍历两个链表，对应项相加并带进位。注意最高位进位时会增加一个节点。 | 链表使用细节比较多，考验C++基础。 | 时间复杂度：$O(max(m,n))$ | 空间复杂度：$O(max(m,n))$ | . | Solution: // Runtime: 28 ms, beats 97.91 % // Memory: 10.4 MB, beats 99.21 % class Solution { public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { ListNode head(0); ListNode *p1 = l1, *p2 = l2, *p = &amp;head; int ans = 0; while (p1 &amp;&amp; p2){ ans = ans / 10 + p1-&gt;val + p2-&gt;val; p-&gt;next = new ListNode(ans%10); p = p-&gt;next; p1 = p1-&gt;next; p2 = p2-&gt;next; } while (p1){ ans = ans / 10 + p1-&gt;val; p-&gt;next = new ListNode(ans%10); p = p-&gt;next; p1 = p1-&gt;next; } while (p2){ ans = ans / 10 + p2-&gt;val; p-&gt;next = new ListNode(ans%10); p = p-&gt;next; p2 = p2-&gt;next; } if (ans / 10 &gt; 0) p-&gt;next = new ListNode(1); return head.next; } }; . | . . 3. Longest Substring Without Repeating Characters . Description: 给定一个字符串，输出其中最大不重复子串。 | . | Analysis: 用unordered_map记录出现过的字符，若出现重复，则从上一个重复字符的索引开始重新遍历。 | 优化：使用start标记子串的开始位置，则不需要索引倒退，实现“一遍过”。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(min(m,n))$，其中$m$是字母集大小。 | . | Solution: // Runtime: 20 ms, beats 90.42 % // Memory Usage: 10.9 MB, beats 98.81 % class Solution { public: int lengthOfLongestSubstring(string s) { unordered_map&lt;int, int&gt; m; const int n = s.size(); int max_len = 0, i = 0, start = 0; while (i &lt; n){ if (m.count(s[i])) start = max(m[s[i]] + 1, start); max_len = max(max_len, i- start + 1); m[s[i++]] = i; } return max_len; } }; . | . . 4. Median of Two Sorted Arrays . Description: 给定两个有序数列，输出两个数列并集的中值。 | . | Analysis: 先确定中值的定义：将数列分隔成等长两个子集，其中左子集始终小于右子集。 | 如果将两个数列分别分隔成左、右两子集，左两子集的并集始终小于右两子集的并集，且两并集等长，则分隔点就是中值。 | 假设用i和j分别将两个数列分隔成两部分，如下： . left_A | right_A A[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1] left_B | right_B B[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] . | 将left_A和left_B、right_A和right_B合并，如下： . left | right A[0], A[1], ..., A[i-1] | A[i], A[i+1], ..., A[m-1] B[0], B[1], ..., B[j-1] | B[j], B[j+1], ..., B[n-1] . | 要使得left始终小于right，只需满足两个条件： A[i-1] &lt; B[j] | B[j-1] &lt; A[i] | . | 要使得left与right等长，即$i+j=m−i+n−j$，这里使： $i = frac{m+n}{2}$ | $j = frac{m+n+1}{2}-i$ （注意：这里+1是为了确保 $j$ 的位置意义与 $i$ 一致，同为右部分的初始位置） | . | 接下来只需寻找满足条件的 $i$ 值即可，可采用二分查找。 | 时间复杂度：$O(log(min(m,n))$， 首先 $i$ 的查找范围为$[0, m]$，使用二分查找，时间复杂度为$O(log(m))$；另外该算法前提是$m&lt;n$，若$m&gt;n$则符号对调，故时间复杂度为$O(log(min(m,n)))$。 | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 24 ms, beats 99.11 % // Memory Usage: 9.6 MB, beats 99.57 % class Solution { public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) { int m = nums1.size(), n = nums2.size(); if (nums1.size() &gt; nums2.size()) return findMedianSortedArrays(nums2, nums1); // 确保m &lt; n,否则j有可能为负数 int imin = 0, imax = m, f = (m + n + 1) / 2; while (imin &lt;= imax){ // 二分查找i值 int i = (imin + imax) / 2; int j = f - i; if (i &gt; imin &amp;&amp; nums1[i-1] &gt; nums2[j]) imax = i - 1; else if (i &lt; imax &amp;&amp; nums2[j-1] &gt; nums1[i]) imin = i + 1; else{ // 边界处理,比较繁琐 int max_left; if (i == 0) max_left = nums2[j-1]; else if (j == 0) max_left = nums1[i-1]; else max_left = max(nums1[i-1], nums2[j-1]); if ((m + n) % 2) return max_left; int min_right; if (i == m) min_right = nums2[j]; else if (j == n) min_right = nums1[i]; else min_right = (min(nums1[i], nums2[j])); return (max_left + min_right) / 2.0; } } return .0; } }; . | . . 5. Longest Palindromic Substring . Description: 给定一个字符串，输出其中最长回文子串。 | . | Analysis: 回文有两种：单核心（如aba）和双核心（如abba）。 | 方法一：中心扩张法。遍历每个字符，以该字符为中心向两边扩张检测回文性，其中要包括的单核心扩张和双核心扩张。 优化：可将遍历范围缩小到$[0,n-maxlen/2]$，其中$maxlen$为目前最大回文子串的长度。 | 优化：由于双核心的回文核心必然是两个相同字符，即使不是双核心回文，如abbba也是回文。故可用left和right标记扩张位置，且遍历核心时right可跳过所有相同字符，直接到达回文右端。无需分类讨论。 | 时间复杂度：$O(n^{2})$ | 空间复杂度：$O(1)$ | . | 方法二：动态规划。若字符串s[i:j]为回文串，则子串s[i-1:j+1]肯定也是回文串，故dp(i,j) = (dp(i-1,j-1) &amp;&amp; s[i] == s[j]) 时间复杂度：$O(n^{2})$ | 空间复杂度：$O(n^{2})$ | . | 方法三：Manacher’s Algorithm（略） | . | Solution: Solution 1: Expand Around Center // Runtime: 4 ms, beats 100.00 % // Memory Usage: 8.8 MB, beats 99.48 % class Solution { public: string longestPalindrome(string s) { int n = s.size(), max_len = 0, start = 0; int i = 0; /* 使用for循环感觉更好看，但runtime从4ms变成16ms for (int i = 0, l = 0, r = 0; i &lt;= n - max_len/2; r = l = ++i){ while (r &lt; n - 1 &amp;&amp; s[r] == s[r+1]) r++; while (l &gt; 0 &amp;&amp; r &lt; n - 1 &amp;&amp; s[l-1] == s[r+1]) l--, r++; int len = r - l + 1; if(max_len &lt; len) max_len = len, start = l; } */ while(i &lt; n - max_len/2){ int l = i, r = i; // 左标记和右标记，各从i开始 while (r &lt; n - 1 &amp;&amp; s[r] == s[r+1]) ++r; // 右标记到连续相同字符的最右，同时解决双核心回文串 i = r + 1; // i从本次回文串核心的下个字符开始，而不是逐个检索。另外不能从本次回文串的下个字符开始，比如ababa while (l &gt; 0 &amp;&amp; r &lt; n - 1 &amp;&amp; s[l-1] == s[r+1]) --l, ++r; // 类似Expand Around Center，从核心向两侧检测回文特性 int len = r - l + 1; if (max_len &lt; len) max_len = len, start = l; } return s.substr(start, max_len); } }; . | Solution 2: Dynamic Programming // Runtime: 108 ms, beats 41.70 % // Memory Usage: 9.9 MB, beats 64.72 % class Solution { public: string longestPalindrome(string s) { const int n = s.size(); if (n &lt; 1) return &quot;&quot;; int max_len = 1, start = 0; bool f[n][n]; // f(i,j) 代表子串s[j,i]是否为回文串 for (int i = 0; i &lt; n; ++i){ f[i][i] = true; for (int j = 0; j &lt; i; ++j){ f[j][i] = (s[i] == s[j] &amp;&amp; (i - j &lt; 2 || f[j+1][i-1])); // 若子串s[j,i]是回文串，且s[i-1] == s[j+1]， 则子串s[j-1,i+1]是回文串 if (f[j][i] &amp;&amp; max_len &lt; (i - j + 1)){ max_len = i - j + 1; start = j; } } } return s.substr(start, max_len); } }; . | . | . . 6. ZigZag Conversion . Description: 给定一个字符串和行数，按行输出其锯齿形状。 | 如输入s = &quot;PAYPALISHIRING&quot;, numRows = 3，输出&quot;PAHNAPLSIIGYIR&quot;，如下： . P A H N A P L S I I G Y I R . | . | Analysis: 这是个找数学规律的算法。锯齿文字中，每个纵列之间的间隔(max_setp)是一定的,而位于斜列上的字符，都按规律将这个间隔分成两部分。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(n)$ | . | Solution: // Runtime: 12 ms, beats 99.49 % // Memory Usage: 10.2 MB, beats 99.79 % class Solution { public: string convert(string s, int numRows) { if (numRows &lt; 2 or s.size() &lt; numRows) return s; const int max_step = (numRows - 1) * 2, n = s.size(); int row = 0, step; string ans; while (row &lt; numRows){ int index = row; if (row == 0 or row == numRows - 1) { step = max_step; while (index &lt; n) ans += s[index], index += step; } else{ bool even = true; while (index &lt; n){ step = even ? max_step - 2 * row : 2 * row; ans += s[index]; index += step; even = !even; } } ++row; } return ans; } }; . | . . 7. Reverse Integer . Description: 给定一个整数，输出其反转后的整数。注意不可溢出($[-2^{32}, 2^{32}-1]$)。 | . | Analysis: 从低位逐位取出数字，从高位逐位放置数字。 | 时间复杂度：$O(n)$，n为输入整数的位数。 | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 4 ms, beats 100.00 % // Memory Usage: 8.1 MB, beats 99.80 % class Solution { public: int reverse(int x) { int ans = 0, b; while (x != 0){ b = x % 10; if (x &gt; 0 &amp;&amp; ans &gt; (INT_MAX - b)/10) return 0; else if (x &lt; 0 &amp;&amp; ans &lt; (INT_MIN - b)/10) return 0; ans = ans * 10 + b; x /= 10; } return ans; } }; . | . . 8. String to Integer (atoi) . Description: 给定一个数字字符串，输出其整型。 | . | Analysis: 细节题，逐位处理即可。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 8 ms, beats 99.69 % // Memory Usage: 8.4 MB, beats 100.00 % class Solution { public: int myAtoi(string str) { const int n = str.size(), ascii_0 = &#39;0&#39;; int i = 0, ans = 0, sign = 1, a; // 处理前端空白字符 while (i &lt; n &amp;&amp; str[i] == &#39; &#39;) ++i; // 处理符号字符 if (i &lt; n &amp;&amp; str[i] == &#39;-&#39;) sign = -1, ++i; else if (i &lt; n &amp;&amp; str[i] == &#39;+&#39;) ++i; // 处理数字字符 while (i &lt; n){ if (isdigit(str[i])){ a = ((int)str[i] - ascii_0) * sign; if (sign &gt; 0 &amp;&amp; ans &gt; (INT_MAX - a)/10) return INT_MAX; else if (sign &lt; 0 &amp;&amp; ans &lt; (INT_MIN - a)/10) return INT_MIN; else ans = ans * 10 + a; } else break; ++i; } return ans; } }; . | . . 9. Palindrome Number . Description: 输出一个整数，判断其是否回文数。 | . | Analysis: 判断是否回文比判断是否存在回文要简单。直接头尾进行判断即可。 | 时间复杂度：$O(n)$，n为输入整数的位数。 | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 32 ms, beats 99.54 % // Memory Usage: 7.9 MB, beats 100.00 % class Solution { public: bool isPalindrome(int x) { if (x &lt; 0) return false; int n = 0, temp = x; while (temp &gt; 0){ temp /= 10; ++n; } int i = 0, end = (n + 1)/2; while (i &lt; end){ if (pickNumIn(x, i) != pickNumIn(x, n - i - 1)) return false; ++i; } return true; } private: int pickNumIn(int x, int i){ // start with 0 while (i-- &gt; 0) x /= 10; return x % 10; } }; . | . . 10. Regular Expression Matching . Description: 给定一个字符串和正则表达式，判断正则表达式是否可以完全表示该字符串。 | . | Analysis: （后记：刚开始为了统一才硬是用英语写分析，毫无语法，以后有空再改写成中文） | Using Dynamic Programming to solve this problem. | While itering, ther are 3 possible situations in p: a-z, &#39;.&#39;, &#39;*&#39;. (assuming i = current substring index in s) a-z : if char is matched and dp[i-1] is true, then dp[i] is true. | | &#39;.&#39; : always matched. | | &#39;*&#39; : (1) if the preceding char is matched, then the &#39;*&#39; combo can means 0, 1 or more this char. | (2) otherwise, the &#39;*&#39; combo can only means 0 (in other word, don’t match) this char. | . | | . | So we can use a matrix called dp to represent how pattern matching the string, initializing with false. | For an example, s = &quot;aaaa&quot;, p = &quot;a*b*&quot;: . &quot;&quot; a a a a &quot;&quot; 0 0 0 0 0 a 0 0 0 0 0 * 0 0 0 0 0 b 0 0 0 0 0 * 0 0 0 0 0 . | step 1.1: preprocessing, set dp[0][0] true because &quot;&quot; do match with &quot;&quot; . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 0 0 0 0 * 0 0 0 0 0 b 0 0 0 0 0 * 0 0 0 0 0 . | step 1.2: &#39;*&#39; can match zero element, so dp[i][0] = dp[i-2][0] meaning &#39;*&#39; and preceding element match nothing. . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 0 0 0 0 * 1 0 0 0 0 b 0 0 0 0 0 * 1 0 0 0 0 . | step 2.1: start itering, if element matches without &#39;*&#39;, then dp[i][j] = dp[i-1][j-1] . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 1 0 0 0 * 1 0 0 0 0 b 0 0 0 0 0 * 1 0 0 0 0 . | step 2.2: if &#39;*&#39; and the preceding element matched, there are 3 meaning about &#39;*&#39;: doesn’t match (dp[i-2][j]), matches one element (dp[i-1][j]), matches several elements (dp[i][j-1]). case 1: match one element: . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 1 0 0 0 * 1 1 0 0 0 b 0 0 0 0 0 * 1 0 0 0 0 . | case 2: match several elements: . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 1 0 0 0 * 1 1 1 1 1 b 0 0 0 0 0 * 1 0 0 0 0 . | case 3: don’t match (in this case do nothing): . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 1 0 0 0 * 1 1 1 1 1 b 0 0 0 0 0 * 1 0 0 0 0 . | . | step 2.3: if &#39;*&#39; and the preceding element doesn’t match, like step 1.2, dp[i][0] = dp[i-2][0] meaning &#39;*&#39; and preceding element match nothing. . &quot;&quot; a a a a &quot;&quot; 1 0 0 0 0 a 0 1 0 0 0 * 1 1 1 1 1 b 0 0 0 0 0 * 1 1 1 1 1 . | Finally dp[n][m] is the result, in this case dp[4][4] is true, while &quot;a*b*&quot; matches &quot;aaaa&quot; . | For another example, s = &quot;aab&quot;, p = &quot;c*a*b&quot;. at last the result is true: . &quot;&quot; a a b &quot;&quot; 1 0 0 0 c 0 0 0 0 * 1 0 0 0 a 0 1 0 0 * 1 1 1 0 b 0 0 0 1 . | Notes: the i and j above are not the same with below, which I use dp[j][i]. | Time Complexity: $O(TP)$, T is the length of the text, P is the length of the pattern. | Space Complexity: $O(TP)$ | . | Solution: // Runtime: 4 ms, beats 100.00 % // Memory Usage: 8.2 MB, beats 100.00 % class Solution { public: bool isMatch(string s, string p) { const int m = s.size(), n = p.size(); int i = 0, j = 0; bool dp[n+1][m+1]; // i - n - p, j - m - s memset(dp, false, sizeof(bool)*(m+1)*(n+1)); // i at string corresponds with i+1 at dp matrix dp[0][0] = true; while (j++ &lt; n){ // scan * while i = 0 if (j &gt; 1 &amp;&amp; p[j-1] == &#39;*&#39;) dp[j][0] = dp[j-2][0]; } while (i++ &lt; m){ j = 0; while (j++ &lt; n){ if (p[j-1] == s[i-1] || p[j-1] == &#39;.&#39;) dp[j][i] = dp[j-1][i-1]; // if not * but match else if (p[j-1] == &#39;*&#39;){ // if * | if (p[j-2] != s[i-1] &amp;&amp; p[j-2] != &#39;.&#39;) dp[j][i] = dp[j-2][i]; // | not match else dp[j][i] = (dp[j-2][i] || dp[j-1][i] || dp[j][i-1]); // | match } } } return dp[n][m]; } }; . | . . 11. Container With Most Water . Description: 给定一个整型数组，输出其柱状图能容纳水的最大体积。 | 例子：[1,8,6,2,5,4,8,3,7]，输出如图： . 9 | 8 area:(8-1)x7=49 8 8 | |_|______________________|_|________7_ 7 | | | 6 | | | | 6 | | | | | 5 | | | | 5 | | | | | | | 4 | | | | 4 | | | | | | | | | | | | | 3 | | | | | 2 | | | | | | | | | | 2 | 1 | | | | | | | | | | | | | | | | 1 | | | | | | | | | | | | | | | | | | | 0 |———| |——| |——| |——| |——| |——| |——| |——| |——| |————— 0 1 2 3 4 5 6 7 8 9 . | . | Analysis: 可以从两边向中间靠拢遍历，两边较小值向中间移动（若值相等可同时向中间移动），并计算并更新最大值。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 20 ms, beats 98.50 % // Memory Usage: 9.7 MB, beats 99.86 % class Solution { public: int maxArea(vector&lt;int&gt;&amp; height) { int l = 0, r = height.size() - 1, ans = 0; while (l &lt; r){ if (height[l] &gt; height[r]) ans = max(ans, height[r] * (r-- - l)); else ans = max(ans, height[l] * (r - l++)); } return ans; } }; . | . . 12. Integer to Roman . Description: 给定一个整数，输出其罗马数字形式。 | . | Analysis: 不想动脑系列，直接用两个数组储存对应的数字和罗马字符串，然后贪心算法换完。 | 优化：用两个整型数组比用unordered_map表现要好。 | 时间复杂度：$O(num)$ | 空间复杂度：$O(1)$ | . | Solution: // Runtime: 16 ms, beats 93.89 % // Memory Usage: 8.3 MB, beats 100.00 % class Solution { public: string intToRoman(int num) { const int integers[] = {1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1}; const string romans[] = {&quot;M&quot;, &quot;CM&quot;, &quot;D&quot;, &quot;CD&quot;, &quot;C&quot;, &quot;XC&quot;, &quot;L&quot;, &quot;XL&quot;, &quot;X&quot;, &quot;IX&quot;, &quot;V&quot;, &quot;IV&quot;, &quot;I&quot;}; const int n = sizeof(integers)/sizeof(int); int i = 0, count; string ans = &quot;&quot;; while (i &lt; n){ if (num &gt;= integers[i]){ count = num / integers[i]; num %= integers[i]; while (count-- &gt; 0) ans += romans[i]; } ++i; } return ans; } }; . | . . 13. Roman to Integer . Description: 给定一个罗马数字字符串，输出其整型形式。 | . | Analysis: 罗马数字一般由大到小，只需留意例如IX的特殊形式即可。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 16 ms, beats 99.47 % // Memory: 8.3 MB, beats 99.85 % class Solution { public: int romanToInt(string s) { int m[256]; m[&#39;I&#39;] = 1, m[&#39;V&#39;] = 5, m[&#39;X&#39;] = 10, m[&#39;L&#39;] = 50, m[&#39;C&#39;] = 100, m[&#39;D&#39;] = 500, m[&#39;M&#39;] = 1000; const int n = s.size(); int i = 0, ans = 0; while (i &lt; n - 1){ if (m[s[i]] &lt; m[s[i+1]]) ans -= m[s[i++]]; else ans += m[s[i++]]; } return ans + m[s[n-1]]; } }; . | . . 14. Longest Common Prefix . Description: 给定一个字符串数组，输出其共有最大前缀。 | . | Analysis: 可采用纵向扫描、横向扫描、分治法、二叉树查找。这里使用纵向扫描。 | 时间复杂度：$O(m)$，这里 $m$ 指所有字符串的总长度。 | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 8 ms, beats 98.46 % // Memory: 8.9 MB MB, beats 99.27 % class Solution { public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) { const int n = strs.size(); if (n == 0) return &quot;&quot;; if (n == 1) return strs[0]; const int m = strs[0].size(); int j = 0, i; string ans = &quot;&quot;; while (j &lt; m){ i = 0; char tmp = strs[i][j]; while (++i &lt; n){ // if (j &gt; strs[i].size()) return ans; if (tmp != strs[i][j]) return ans; } ans += tmp; ++j; } return ans; } }; . | . . 15. 3Sum . Description: 给定一个数组，输出其中三数之和为零的所有组合。 | . | Analysis: 先对数组排序，然后遍历先固定一个数字，然后剩下两数用左右夹逼找出。遍历时只需遍历前$n-2$个元素。 | 优化：遍历时可只遍历非正数，因为有序序列正数后面必然都是正数，不可能存在之和为零。 | 时间复杂度：$O(n^{2})$ | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 96 ms, beats 98.42 % // Memory: 14.7 MB, beats 99.30 % class Solution { public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) { const int n = nums.size(); vector&lt;vector&lt;int&gt;&gt; ans; if (n &lt; 3) return ans; sort(nums.begin(), nums.end()); const int target = 0; int i = 0, l, r, sum; while (nums[i] &lt;= 0 &amp;&amp; i &lt; n - 2){ if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) { ++i; continue; } l = i + 1, r = n - 1; while (l &lt; r){ sum = nums[i] + nums[l] + nums[r]; if (sum &lt; target) ++l; else if (sum &gt; target) --r; else { ans.push_back({nums[i], nums[l], nums[r]}); do {++l;} while (nums[l] == nums[l-1] &amp;&amp; l &lt; r); do {--r;} while (nums[r] == nums[r+1] &amp;&amp; l &lt; r); } } ++i; } return ans; } }; . | . . 16. 3Sum Closest . Description: 给定一个数组和一个目标数target，输出其中三数之和最接近于target的值。 | . | Analysis: 先对数组排序，然后遍历先固定一个数字，然后剩下两数用左右夹逼找出。遍历时只需遍历前$n-2$个元素。 | 时间复杂度：$O(n^{2})$ | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 8 ms, beats 99.98 % // Memory: 8.5 MB, beats 100 % class Solution { public: int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) { const int n = nums.size(); int i = 0, max_offset = INT_MAX, sum, ans, l, r; sort(nums.begin(), nums.end()); while (i &lt; n - 2){ if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]){ ++i; continue; } l = i + 1, r = n - 1; while (l &lt; r){ sum = nums[i] + nums[l] + nums[r]; if (abs(sum - target) &lt; max_offset) { ans = sum; max_offset = abs(sum - target); if (max_offset == 0) return ans; } if (sum &gt; target) --r; else if (sum &lt; target) ++l; } ++i; } return ans; } }; . | . . 17. Letter Combinations of a Phone Number . Description: 给定一个数字字符串，输出其在座机9键对应的字符串输出的所有可能。 | 如图： . _______________________________ | 1 | 2 | 3 | | / | a b c | d e f | |_________|_________|_________| | 4 | 5 | 6 | | g h i | j k l | m n o | |_________|_________|_________| | 7 | 8 | 9 | | p q r s | t u v | w s y z | |_________|_________|_________| | * | 0 | # | | / | / | / | |_________|_________|_________| . | . | Analysis: 使用DFS(深度优先搜索)递归解决，每递归一次处理一个数字。 | 时间复杂度：$O(3^{M} times 4^{N})$，$M$ 是对应字母数为3的数字的个数，$N$ 是对应字母数为4的数字的个数。 | 空间复杂度：$O(3^{M} times 4^{N})$ | . | Analysis: // Runtime: 4 ms, beats 100.00 % // Memory: 8.5 MB, beats 93.83 % class Solution { public: vector&lt;string&gt; letterCombinations(string digits) { const int n = digits.size(); vector&lt;string&gt; ans; string cal[8] = {&quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot;}; if (n &gt; 0) digits2letter(digits, &quot;&quot;, ans, cal); return ans; } private: void digits2letter(string digits, string tmp, vector&lt;string&gt; &amp;ans, string cal[]) { if (digits == &quot;&quot;) { ans.push_back(tmp); return; } else{ string s = cal[int(digits[0]) - &#39;2&#39;]; for (int i = 0; i &lt; s.size(); ++i){ string t = tmp; t += s[i]; digits2letter(digits.substr(1), t, ans, cal); } } } }; . | . . 18. 4Sum . Description: 给定一个数组和一个目标数target，输出其中四数之和等于target的所有组合。 | . | Analysis: 同3sum，先遍历固定两个数，然后剩下两数用左右夹逼找出。 | 优化：可用unordered_map储存两数之和，剩下只需遍历剩余两数，时间复杂度为$O(n^{2})$。但去重比较复杂。 | 时间复杂度：$O(n^{3})$ | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 8 ms, beats 99.87 % // Memory: 9.2 MB, beats 76.04 % class Solution { public: vector&lt;vector&lt;int&gt;&gt; fourSum(vector&lt;int&gt;&amp; nums, int target) { const int n = nums.size(); vector&lt;vector&lt;int&gt;&gt; ans; if (n &lt; 4) return ans; sort(nums.begin(), nums.end()); int l, r, sum; for (int i = 0; i &lt; n - 3; ++i){ if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) continue; if (nums[i] + nums[n-1] + nums[n-2] + nums[n-3] &lt; target) continue; if (nums[i] + nums[i+1] + nums[i+2] + nums[i+3] &gt; target) break; for (int j = i + 1; j &lt; n - 2; ++j){ if (j &gt; i + 1 &amp;&amp; nums[j] == nums[j-1]) continue; l = j + 1; r = n - 1; while (l &lt; r){ sum = nums[i] + nums[j] + nums[l] + nums[r]; if (sum &lt; target) ++l; else if (sum &gt; target) --r; else { ans.push_back({nums[i], nums[j], nums[l], nums[r]}); do {++l;} while (nums[l] == nums[l-1] &amp;&amp; l &lt; r); do {--r;} while (nums[r] == nums[r+1] &amp;&amp; l &lt; r); } } } } return ans; } }; . | . . 19. Remove Nth Node From End of List . Description: 给定一个链表和n，返回去掉倒数第n个结点的链表。 | . | Analysis: 采用双指针p1、p2，指针p1先走n步，然后两个指针一起走。当指针p1到链表尾，去掉指针p2所指元素即可。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(1)$ | . | Analysis: // Runtime: 4 ms, beats 99.26 % // Memory: 8.5 MB, beats 81.15 % class Solution { public: ListNode* removeNthFromEnd(ListNode* head, int n) { ListNode dummy(-1); dummy.next = head; ListNode *p1 = &amp;dummy, *p2 = p1; int i = 0; while (i++ &lt; n) p1 = p1-&gt;next; while (p1-&gt;next) { p1 = p1-&gt;next; p2 = p2-&gt;next; } p2 -&gt;next = p2-&gt;next-&gt;next; return dummy.next; } }; . | . . 20. Valid Parentheses . Description: 实现括号匹配。 | . | Analysis: 简单的栈问题。 | 时间复杂度：$O(n)$ | 空间复杂度：$O(n)$ | . | Analysis: // Runtime: 0 ms, beats 100.00 % // Memory: 8.7 MB, beats 55.72 % class Solution { public: bool isValid(string s) { const int n = s.size(); if (n &lt; 2) return n&amp;0x01 == 1 ? false : true; stack&lt;char&gt; stack; int i = 0; while (i &lt; n){ if (s[i] == &#39;[&#39; || s[i] ==&#39;{&#39; || s[i] == &#39;(&#39;) { stack.push(s[i]); } else { if (stack.empty()) return false; else if (s[i] == &#39;]&#39; &amp;&amp; stack.top() != &#39;[&#39;) return false; else if (s[i] == &#39;)&#39; &amp;&amp; stack.top() != &#39;(&#39;) return false; else if (s[i] == &#39;}&#39; &amp;&amp; stack.top() != &#39;{&#39;) return false; stack.pop(); } ++i; } return stack.empty() ? true : false; } }; . | . .",
            "url": "https://bjchacha.github.io/myblog/algorithm/2019/05/15/leetcode-practise.html",
            "relUrl": "/algorithm/2019/05/15/leetcode-practise.html",
            "date": " • May 15, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Windows 个人软件收藏集",
            "content": "Sumatra PDF . 开源的轻量级PDF阅读器 | 适合追求轻量PDF阅读体验的用户 | . Calibre . 本地电子书管理工具 | 适合有kindle或者喜欢看电子书的用户 | . Motrix . 开源、跨平台的下载工具 | 支持下载 HTTP、FTP、BT、磁力链、百度网盘等资源 | 界面简洁 | . Rufus . 开源的可引导USB盘创建工具 | 支持多种系统镜像 | 速度很快 | . Office Tool Pro &amp; Lite . 免费的Office快速部署工具 | 一键下载、安装、激活各种版本Office | KMS地址：上网找吧挺多的 | . QuickLook . 按空格就可以预览文件内容 | 支持大多数格式文件，包括文本、图片、视频、压缩文件等 | 快！方便！ | . Listary . 文件检索系统+启动器 | 支持快捷键启动，启动速度快，搜索速度一流 | 支持常用操作命令，比如百度搜索等 | 免费够用 | 还有很多强大的功能 | . 待续…… .",
            "url": "https://bjchacha.github.io/myblog/software/2018/04/30/windows-great-software-collections.html",
            "relUrl": "/software/2018/04/30/windows-great-software-collections.html",
            "date": " • Apr 30, 2018"
        }
        
    
  
    
        ,"post11": {
            "title": "在Ubuntu快速部署Django",
            "content": "配置环境 . Ubuntu 16.04-64bit | Python 3.5 | Django 2.0.4 | . 第零步 部署准备工作 . 编写requirements.txt文件(根据自身情况编写) . Django==2.0.4 django-pagedown==1.0.4 Markdown==2.6.11 Pygments==2.2.0 . 关闭项目的DEBUG模式 /mysite/mysite/settings.py . ... DEBUG = True # 关闭DEBUG模式 ALLOWED_HOSTS = [&#39;*&#39;] # 允许访问的域名，&#39;*&#39;表示允许所有 LANGUAGE_CODE = &#39;en_us&#39; # Ubuntu中Django不包含中文语言包 TIME_ZONE = &#39;Asia/Shanghai&#39; # 修改时区 . 本示例项目名字为mysite,后面内容请根据自身情况修改 然后把项目和requirements.txt上传到服务器 将项目放在/home,即项目目录为/home/mysite(即manage.py文件所在目录) . . 第一步 更新系统 . sudo apt-get update sudo apt-get upgrade . . 第二步(可选) 安装Python3.6 . sudo apt-get install build-essential checkinstall sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev cd /etc/ wget https://www.python.org/ftp/python/3.6.4/Python-3.6.4.tgz sudo tar xzf Python-3.6.4.tgz cd Python-3.6.4 sudo ./configure sudo make altinstall . . 第三步 安装项目依赖项 . pip3 install -r requirements.txt . . 第四步 项目在服务器中初始化 . python manage.py makemigrations python manage.py migrate python manage.py createsuperuser # 若数据库中已有管理员账号则可跳过 python manage.py collectstatic . 测试 . python manage.py runserver 0.0.0.0:80 . 访问公网ip，能显示项目内容，但可能无法显示静态文件内容 杀掉80端口 . fuser -k 80/tcp . . 第五步 安装uWSGI . pip3 install uwsgi . 测试 . uwsgi –http :80 –chdir /home/mysite/ -w mysite.wsgi . 访问公网ip，访问正常则退出并继续 . mkdir -p /etc/uwsgi/sites cd /etc/uwsgi/sites nano mysite.ini . 输入以下内容 . [uwsgi] project = mysite base = /home chdir = %(base)/%(project) module = %(project).wsgi:application master = true processes = 5 socket = %(base)/%(project)/%(project).sock chmod-socket = 666 vacuum = true . . 第六步 安装Nginx . apt-get install nginx nano /etc/nginx/sites-available/mysite . 输入以下内容 . server { listen 80; server_name yourdomain.com; location /static/ { root /home/mysite; } location / { include uwsgi_params; uwsgi_pass unix:/home/mysite/mysite.sock; } } . 其中yourdomain.com改成自己的域名(假设已经完成解析设置) . 链接文件并检测nginx服务器 . ln -s /etc/nginx/sites-available/mysite /etc/nginx/sites-enabled/ service nginx configtest . (可能需要)删除nginx默认模板 . rm -r /etc/nginx/sites-available/default . . 第七步 启动服务 . service nginx restart uwsgi /etc/uwsgi/sites/mysite.ini -d /home/mysite/mysite.log . 访问域名，能够正常访问，静态文件也能正常显示 . . 最终步 欢呼吧！ . 来源 .",
            "url": "https://bjchacha.github.io/myblog/django/2018/04/30/ubuntu-django-deployment.html",
            "relUrl": "/django/2018/04/30/ubuntu-django-deployment.html",
            "date": " • Apr 30, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://bjchacha.github.io/myblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://bjchacha.github.io/myblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}